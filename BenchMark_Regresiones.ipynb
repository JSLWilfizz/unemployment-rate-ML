{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Descarga de librerias necesarias**"
      ],
      "metadata": {
        "id": "4ZM8Ei6LE_XT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score \n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score \n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.constraints import NonNeg\n",
        "from tensorflow import keras\n",
        "import os\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9L5xymsllmL",
        "outputId": "f1e18f29-5376-4a5f-aaca-3f9a86265a81"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-23.5.9-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-23.5.9 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "xnxC9up58Bsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data completa**"
      ],
      "metadata": {
        "id": "b-YLxSdgyH4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"Datos_imputados_data_2.csv\", parse_dates=[\"Fecha\"]) # Agrega el path de la data\n",
        "del df[\"Unnamed: 0\"]\n",
        "df.index = df[\"Fecha\"]\n",
        "\n",
        "fecha_inicio = pd.to_datetime('2020-04-01')  # Inicio corte\n",
        "fecha_fin = pd.to_datetime('2021-10-01')  # Fin corte\n",
        "\n",
        "filtro_fechas = (df.index >= fecha_inicio) & (df.index <= fecha_fin)\n",
        "df.loc[~filtro_fechas].to_csv(\"Datos Filtrados.csv\")\n",
        "df[\"Tasa de desocupación \"].loc[~filtro_fechas].to_csv(\"Tasa Filtradas.csv\")\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "# Variable de entrada\n",
        "X = scaled_data\n",
        "# Variable de salida\n",
        "Y = df[\"Tasa de desocupación \"].values\n",
        "\n",
        "#per_train = float(input(\"Ingresar % de datos de entrenamiento: (EJ: 0.8)\"))\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
        "#                                                    train_size=1,\n",
        "#                                                    random_state= 10\n",
        "#                                                   )"
      ],
      "metadata": {
        "id": "TaPZjeldyEKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "4e5d60ed-6cd9-412a-f474-b05e84d54f83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-47a6da93c7c7>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tasa de desocupación \"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mfiltro_fechas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tasa Filtradas.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mscaled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Tasa de desocupación \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fecha\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Variable de entrada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5fiP4VcwhFt",
        "outputId": "362619cc-85ff-4987-92ec-2758427a97bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Índice de Producción Industrial1/Ref/P',\n",
              "       'Imacec empalmado, desestacionalizado (índice 2018=100)',\n",
              "       'Índice de Actividad del Comercio al por Menor empalmado1/Ref/P/R',\n",
              "       'Superficie total1/P', 'M1', 'M2', 'M3', '1.Tasas BCP 10 años',\n",
              "       'Captaciones 30 a 89 Dias Reaj. Nominal.',\n",
              "       'Colocaciones 90 a 365 Dias Reaj. U.F.', 'Índice IPC', 'Índice IPP',\n",
              "       '1.IPSA  (índice enero 2003=1000)', 'Índice Real de Remuneraciones',\n",
              "       '1.Índice de Avisos Laborales de Internet', 'Price_Copper',\n",
              "       'Price_oil_WTI', 'Tasa de desocupación ', 'Fecha'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data filtrada**\n",
        "\n",
        "Columnas a Usar\n",
        "```\n",
        "'Índice de Producción Industrial1/Ref/P',\n",
        "'Imacec empalmado, desestacionalizado (índice 2018=100)',\n",
        "'Índice de Actividad del Comercio al por Menor empalmado1/Ref/P/R',\n",
        "'Superficie total1/P', \n",
        "'M1', \n",
        "'M2', \n",
        "'M3', \n",
        "'1.Tasas BCP 10 años',\n",
        "'Captaciones 30 a 89 Dias Reaj. Nominal.',\n",
        "'Colocaciones 90 a 365 Dias Reaj. U.F.', \n",
        "'Índice IPC', \n",
        "'Índice IPP',\n",
        "'1.IPSA  (índice enero 2003=1000)', \n",
        "'Índice Real de Remuneraciones',\n",
        "'1.Índice de Avisos Laborales de Internet', \n",
        "'Price_Copper',\n",
        "'Price_oil_WTI', \n",
        "'Tasa de desocupación ',\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "bcSsnbuwyJga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "  \n",
        "df = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[:-3] # Agregar path de la data\n",
        "del df[\"Unnamed: 0\"]\n",
        "df = df[df.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "#df.to_csv(\"drive/MyDrive/output_benchmark/Datos Imputados y Filtrados.csv\")\n",
        "df.index = pd.to_datetime(df[\"Fecha\"])\n",
        "'''\n",
        "fecha_inicio = pd.to_datetime('2020-04-01')#Inicio corte\n",
        "fecha_fin = pd.to_datetime('2021-10-01')#Fin corte\n",
        "\n",
        "filtro_fechas = (df.index >= fecha_inicio) & (df.index <= fecha_fin)\n",
        "df = df.drop(df.loc[filtro_fechas, 'Tasa de desocupación '].index,axis=0)\n",
        "'''\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "# Variable de entrada\n",
        "X = scaled_data\n",
        "# Variable de salida\n",
        "Y = df[\"Tasa de desocupación \"].values"
      ],
      "metadata": {
        "id": "p7kJJa3g8FLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0v-Jsh4LJQR",
        "outputId": "68cbde65-6db1-4744-8676-fdff23f8e66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RandomForestRegressor**\n",
        "\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros \n",
        "  - Parametros a buscar:\n",
        "    1.   random_state\n",
        "    2.   max_depth\n",
        "    3. criterion\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jDwkLVK56hpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U38ORJnU4l0p",
        "outputId": "a55da413-ca89-41d0-c1d3-c58926328f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        }
      ],
      "source": [
        "opt = BayesSearchCV(\n",
        "    RandomForestRegressor(),\n",
        "    {\n",
        "        'random_state': Integer(0, 5, prior='uniform'),\n",
        "        'max_depth': Integer(1, 5, prior='uniform'),\n",
        "        'criterion': Categorical([\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]),\n",
        "\n",
        "    },\n",
        "    n_iter=40,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X, Y) \n",
        "# aqui termina la busqueda\n",
        "\n",
        "# model can be saved, used for predictions or scoring\n",
        "\n",
        "#y_pred = (opt.predict(X_test))\n",
        "\n",
        "#ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha RFR\"])\n",
        "#testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "#pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "#r2 = r2_score(\n",
        "#    y_true=y_test,\n",
        "#    y_pred = y_pred)\n",
        "#print(f\"El valor de R2 es:{r2}\")\n",
        "#mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "#print(f\"El valor de MSE es:{mse}\")\n",
        "#rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "#print(f\"El valor de RMSE es:{rmse}\")\n",
        "##Guardando Modelo\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_RandomForestRegressor.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVR**\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros\n",
        "  - Parametros a buscar:\n",
        "    1.   C\n",
        "    2.   epsilon\n",
        "    3. kernel\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n"
      ],
      "metadata": {
        "id": "vTo7eDH96NNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afB3LVdQOeVC",
        "outputId": "9c6e6b4c-a2a3-4351-e69a-449a1ca31b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score \n",
        "import pickle\n",
        "\n",
        "\n",
        "results = pd.DataFrame(columns= [\"Iteracion\",\"C\",\"epsilon\",\"kernel\",\"R2\",\"Path\"])\n",
        "numero_iteracion = 0\n",
        "iteraciones = []\n",
        "C_ = []\n",
        "epsilon_ = []\n",
        "kernel_ = []\n",
        "r2_ = []\n",
        "path_model_= []\n",
        "\n",
        "\n",
        "# log-uniform: understand as search over p = exp(x) by varying x\n",
        "opt = BayesSearchCV(\n",
        "    SVR(),\n",
        "    {\n",
        "        'C': Real(.01, 100, prior='log-uniform'),\n",
        "        'epsilon': Real(.0001, 2, prior='log-uniform'),\n",
        "        'kernel': Categorical(['linear', 'poly', 'rbf']),\n",
        "\n",
        "    },\n",
        "    n_iter=100,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X, Y)\n",
        "\n",
        "# model can be saved, used for predictions or scoring\n",
        "#y_pred = opt.predict(X_test)\n",
        "\n",
        "#newdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha SVR\"])\n",
        "#testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "#pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "#r2 = r2_score(\n",
        "#    y_true=y_test,\n",
        "#    y_pred = y_pred)\n",
        "#\n",
        "#\n",
        "#r2 = r2_score(\n",
        "#    y_true=y_test,\n",
        "#    y_pred = y_pred)\n",
        "#print(f\"El valor de R2 es:{r2}\")\n",
        "#mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "#print(f\"El valor de MSE es:{mse}\")\n",
        "#rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "#print(f\"El valor de RMSE es:{rmse}\")\n",
        "#Guardando Modelo\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_SVR.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "SgQTqT1F6pbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multi-layer Perceptron regressor.**\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros\n",
        "  - Parametros a buscar:\n",
        "    1.   alpha\n",
        "    2.   epsilon\n",
        "    3. activation\n",
        "    4. solver\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n"
      ],
      "metadata": {
        "id": "Eshm_YdJuK4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score \n",
        "import pickle\n",
        "\n",
        "\n",
        "results = pd.DataFrame(columns= [\"Iteracion\",\"C\",\"epsilon\",\"kernel\",\"R2\",\"Path\"])\n",
        "numero_iteracion = 0\n",
        "iteraciones = []\n",
        "C_ = []\n",
        "epsilon_ = []\n",
        "kernel_ = []\n",
        "r2_ = []\n",
        "path_model_= []\n",
        "\n",
        "\n",
        "# log-uniform: understand as search over p = exp(x) by varying x\n",
        "opt = BayesSearchCV(\n",
        "    MLPRegressor(),\n",
        "    {\n",
        "        'alpha': Real(.0001, 1, prior='log-uniform'),\n",
        "        'epsilon': Real(.0001, 2, prior='log-uniform'),\n",
        "        'activation': Categorical(['identity', 'logistic', 'tanh', 'relu']),\n",
        "        'solver': Categorical(['lbfgs', 'sgd', 'adam'])\n",
        "\n",
        "    },\n",
        "    n_iter=100,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X, Y)\n",
        "'''\n",
        "# model can be saved, used for predictions or scoring\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha MLPRegressor\"])\n",
        "testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "print(f\"El valor de R2 es:{r2}\")\n",
        "mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "print(f\"El valor de MSE es:{mse}\")\n",
        "rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "print(f\"El valor de RMSE es:{rmse}\")'''\n",
        "#Guardando Modelo\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_MLPRegressor.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "hIJn8ctxcIsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lasso Regression**\n",
        "\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros\n",
        "  - Parametros a buscar:\n",
        "    1.   alpha\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MzpjpiXjwQ6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score \n",
        "import pickle\n",
        "\n",
        "\n",
        "results = pd.DataFrame(columns= [\"Iteracion\",\"C\",\"epsilon\",\"kernel\",\"R2\",\"Path\"])\n",
        "numero_iteracion = 0\n",
        "iteraciones = []\n",
        "C_ = []\n",
        "epsilon_ = []\n",
        "kernel_ = []\n",
        "r2_ = []\n",
        "path_model_= []\n",
        "\n",
        "\n",
        "# log-uniform: understand as search over p = exp(x) by varying x\n",
        "opt = BayesSearchCV(\n",
        "    Lasso(),\n",
        "    {\n",
        "        'alpha': Real(.0001, 1, prior='log-uniform')\n",
        "\n",
        "    },\n",
        "    n_iter=100,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X_train, y_train)\n",
        "'''\n",
        "# model can be saved, used for predictions or scoring\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha Lasso\"])\n",
        "testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "print(f\"El valor de R2 es:{r2}\")\n",
        "mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "print(f\"El valor de MSE es:{mse}\")\n",
        "rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "print(f\"El valor de RMSE es:{rmse}\")'''\n",
        "#Guardando Modelo\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "  \n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_Lasso.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fsckfarcu22",
        "outputId": "e52a5b7f-8e8e-427f-9d66-3b94973c502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.713e-01, tolerance: 2.431e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+00, tolerance: 2.388e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.133e-01, tolerance: 2.649e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.469e-01, tolerance: 2.767e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.228e-01, tolerance: 2.727e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+00, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+00, tolerance: 2.782e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.505e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.958e-01, tolerance: 2.437e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.181e-01, tolerance: 2.258e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.826e-02, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.025e-02, tolerance: 2.782e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e-01, tolerance: 2.431e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e-01, tolerance: 2.388e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.818e-02, tolerance: 2.649e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.939e-02, tolerance: 2.767e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e-02, tolerance: 2.727e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e-01, tolerance: 2.782e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.933e-02, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-01, tolerance: 2.437e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e-01, tolerance: 2.258e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.575e-01, tolerance: 2.431e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.317e-01, tolerance: 2.388e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.800e-01, tolerance: 2.649e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.792e-01, tolerance: 2.767e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.616e-01, tolerance: 2.727e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.677e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.064e+00, tolerance: 2.782e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.832e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.786e-01, tolerance: 2.437e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.877e-01, tolerance: 2.258e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e-01, tolerance: 2.431e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.337e-01, tolerance: 2.388e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e-01, tolerance: 2.649e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e-01, tolerance: 2.767e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e-01, tolerance: 2.727e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.944e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.827e-01, tolerance: 2.782e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.967e-01, tolerance: 2.625e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e-01, tolerance: 2.437e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.996e-01, tolerance: 2.258e-02\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DecisionTreeRegressor**\n",
        "\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros\n",
        "  - Parametros a buscar:\n",
        "   1.   max_depth\n",
        "\n",
        "\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n2a2-8XLwVbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skopt import BayesSearchCV\n",
        "# parameter ranges are specified by one of below\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score \n",
        "import pickle\n",
        "\n",
        "\n",
        "results = pd.DataFrame(columns= [\"Iteracion\",\"C\",\"epsilon\",\"kernel\",\"R2\",\"Path\"])\n",
        "numero_iteracion = 0\n",
        "iteraciones = []\n",
        "C_ = []\n",
        "epsilon_ = []\n",
        "kernel_ = []\n",
        "r2_ = []\n",
        "path_model_= []\n",
        "\n",
        "\n",
        "# log-uniform: understand as search over p = exp(x) by varying x\n",
        "opt = BayesSearchCV(\n",
        "    DecisionTreeRegressor(),\n",
        "    {\n",
        "        'max_depth': Integer(1, 10, prior='log-uniform')\n",
        "\n",
        "    },\n",
        "    n_iter=10,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X, Y)\n",
        "'''\n",
        "# model can be saved, used for predictions or scoring\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha SVR\"])\n",
        "testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "print(f\"El valor de R2 es:{r2}\")\n",
        "mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "print(f\"El valor de MSE es:{mse}\")\n",
        "rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "print(f\"El valor de RMSE es:{rmse}\")\n",
        "\n",
        "'''\n",
        "#Guardando Modelo\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "  \n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_DecisionTreeRegressor.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "6bsmrCGFu3Sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **KNeighborsRegressor**\n",
        "\n",
        "- Utiliza una busqueda bayesiana para los hyperparametros\n",
        "  - Parametros a buscar:\n",
        "    1.   n_neighbors\n",
        "    2. algorithm\n",
        "\n",
        "*   cv = Cross-validation\n",
        "*   iter = Iteraciones\n",
        "\n"
      ],
      "metadata": {
        "id": "peEwi4BNwZCZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "results = pd.DataFrame(columns= [\"Iteracion\",\"C\",\"epsilon\",\"kernel\",\"R2\",\"Path\"])\n",
        "numero_iteracion = 0\n",
        "iteraciones = []\n",
        "C_ = []\n",
        "epsilon_ = []\n",
        "kernel_ = []\n",
        "r2_ = []\n",
        "path_model_= []\n",
        "\n",
        "\n",
        "# log-uniform: understand as search over p = exp(x) by varying x\n",
        "opt = BayesSearchCV(\n",
        "    KNeighborsRegressor(),\n",
        "    {\n",
        "        'n_neighbors': Integer(1, 10, prior='log-uniform'),\n",
        "        'algorithm': Categorical(['auto', 'ball_tree', 'kd_tree','brute'])\n",
        "\n",
        "    },\n",
        "    n_iter=40,\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "# executes bayesian optimization\n",
        "_ = opt.fit(X, Y)\n",
        "'''\n",
        "# model can be saved, used for predictions or scoring\n",
        "y_pred = opt.predict(X_test)\n",
        "\n",
        "ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha SVR\"])\n",
        "testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "\n",
        "pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "print(f\"El valor de R2 es:{r2}\")\n",
        "mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "print(f\"El valor de MSE es:{mse}\")\n",
        "rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "print(f\"El valor de RMSE es:{rmse}\")\n",
        "#Guardando Modelo'''\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta que se va a generar en el drive\n",
        "if os.path.isdir(data_folder) == False: # Ask if the folder exist, if return a false create the folder\n",
        "  os.mkdir(data_folder)\n",
        "filename = 'drive/MyDrive/output_benchmark/finalized_model_KNN.sav'\n",
        "pickle.dump(_, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PuhICwMvXIu",
        "outputId": "46798bf0-2651-43b5-eec7-ee48383e434e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.10/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CgWHfl-cmAzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM MultiVariate**\n",
        "- Optimización utilizando hypeband, buscar hyperband al final del Colab\n",
        "- Se hace un reshape de los datos de entrenamiento y testeo\n",
        "- **Copiar los resultados del hyperband en la creación del modelo**"
      ],
      "metadata": {
        "id": "iK1W0i0L68N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score \n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.constraints import NonNeg\n",
        "from tensorflow import keras\n",
        "# Cargar los datos\n",
        "#df = pd.read_csv(\"Datos_imputados.csv\")\n",
        "\n",
        "X_train_ = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])) \n",
        "X_test_ = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Crear el modelo LSTM\n",
        "model = Sequential()\n",
        "#Se escribe a mano los resultados del hyperband que se ejecuta al final del colab\n",
        "model.add(LSTM(68, activation='relu', input_shape=(1, X_train_.shape[2])))\n",
        "model.add(Dense(units=92,activation='relu',kernel_initializer='HeNormal'))\n",
        "model.add(Dense(units=164,activation='relu',kernel_initializer='HeNormal'))\n",
        "model.add(Dense(units=296,activation='relu',kernel_initializer='HeNormal'))\n",
        "model.add(Dense(1, activation='linear',kernel_initializer='normal')) \n",
        "###################\n",
        "model.compile(optimizer=keras.optimizers.Adam(0.01), loss='mse',)\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train_, y_train, epochs=100, batch_size=3, verbose=1)\n",
        "\n",
        "# Realizar predicciones\n",
        "x_input = X_test\n",
        "y_pred = model.predict(x_input)\n",
        "\n",
        "ynewdf = pd.DataFrame(data = y_pred,columns=[\"Tasa de desocupación predicha LSTM\"])\n",
        "testYdf = pd.DataFrame(data = y_test)\n",
        "\n",
        "pd.concat([testYdf.reset_index().drop(\"index\",axis=1),ynewdf],axis=1).plot()\n",
        "\n",
        "r2 = r2_score(\n",
        "    y_true=y_test,\n",
        "    y_pred = y_pred)\n",
        "print(f\"El valor de R2 es:{r2}\")\n",
        "mse = mean_squared_error(y_test,y_pred,squared=True) # True calcula el MSE\n",
        "print(f\"El valor de MSE es:{mse}\")\n",
        "rmse = mean_squared_error(y_test,y_pred,squared=False)# False calcula el RMSE\n",
        "print(f\"El valor de RMSE es:{rmse}\")"
      ],
      "metadata": {
        "id": "B3ndeOz_6-sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperband LSTM\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> Primer paso\n",
        "\n",
        "Se define la neurona inicial:\n",
        "\n",
        "```\n",
        "model.add(LSTM(68, activation='relu', input_shape=(1, X_train_.shape[2])))\n",
        "```\n",
        "\n",
        "> Segundo paso\n",
        "\n",
        " Para cambiar los parametros de busqueda en el hyperband se modifica en primer lugar: `for i in range(hp.Int('num_of_layers',2,10))` para cambiar el rango de el numero de layers a utilizar en este caso son de 2 a 10.\n",
        "\n",
        "> Tercer paso\n",
        "\n",
        "Las Capas Dense donde se modifican el numero de neuronas que cada una puede tener.\n",
        "\n",
        "```\n",
        "# model.add(Dense(units=hp.Int('num_of_neurons'+ str(i),min_value=20,max_value=312,step=12),\n",
        "                                    activation='relu',kernel_initializer='HeNormal'))\n",
        "```\n",
        "\n",
        "\n",
        "> Cuarto paso\n",
        "\n",
        "Modificar los valores del optimizador.\n",
        "```\n",
        "# model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning rate',values=[1e-2, 1e-3, 1e-4])),loss='mse',\n",
        "                  metrics=['mse'])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zAonjexdySdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n",
        "from keras_tuner import Hyperband\n",
        "\n",
        "\n",
        "\n",
        "def build_model(hp): # Función de hyperband\n",
        "    model=Sequential()\n",
        "    model.add(LSTM(68, activation='relu', input_shape=(1, X_train_.shape[2])))\n",
        "    for i in range(hp.Int('num_of_layers',2,30)):         \n",
        "      #providing range for number of neurons in hidden layers\n",
        "      #Activation Opciones : sigmoid,relu, LeakyRelu , relu entrega los mejores resultados para este caso.\n",
        "      # Como son numeros positivos relativamente altos, es recomendado utilizar relu.\n",
        "      # En caso contrario, probar utilizar Sigmoid o Leakyrelu\n",
        "       model.add(Dense(units=hp.Int('num_of_neurons'+ str(i),min_value=20,max_value=312,step=12),\n",
        "                                    activation='relu',kernel_initializer='HeNormal'))\n",
        "    model.add(Dense(1, activation='linear',kernel_initializer='normal'))    #output layer\n",
        "    #compiling the model\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning rate',values=[1e-2, 1e-3, 1e-4])),loss='mse',\n",
        "                  metrics=['mse'])\n",
        "    return model\n",
        "#Inicia el Hyperband\n",
        "X_train_ = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])) \n",
        "X_test_ = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tuner=Hyperband(build_model, objective='mse',\n",
        "                    directory='Hyperband Opt4', project_name= 'fixed2')\n",
        "tuner.search(X_train_,y_train,epochs=1,validation_data=(X_test_,y_test))\n",
        "#\n",
        "#Resultados\n",
        "tuner.results_summary()"
      ],
      "metadata": {
        "id": "h7URRYIQyUqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cargando Modelos**\n",
        "\n",
        "Modelos disponibles para testeo se utiliza la misma data de test. \n",
        "\n",
        "*   finalized_model_KNN.sav (KNN)\n",
        "*   finalized_model_DecisionTreeRegressor.sav (DTR)\n",
        "*   finalized_model_Lasso.sav (Lasso)\n",
        "*   finalized_model_MLPRegressor.sav (MLP)\n",
        "*   finalized_model_SVR.sav (SVR)\n",
        "*   finalized_model_RandomForestRegressor.sav (RFR)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Los modelos se crearan luego de ejecutar por primera ves los codigos.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Os2qBq8uE2oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_SVR.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "SVR = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha SVR\"])\n"
      ],
      "metadata": {
        "id": "qPxOTJQTPs0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4da55b44-ce6b-486f-de27-9bb228bf2a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[7.93115571 8.2211726  8.07702477]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_Lasso.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "lasso = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha LASSO\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JF5WgG-8hix",
        "outputId": "154a54d0-6793-43d0-c01d-33c58f4004a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[10.52981326 18.62448785  8.13423605]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_RandomForestRegressor.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "RFR = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha RFR\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBf_j7tTEUMA",
        "outputId": "578dda47-f8f6-400f-a997-730964b84e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[ 7.77583422  7.77695067 10.55810894]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_KNN.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "KNN = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha KNN\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEmWilSD7nDr",
        "outputId": "bdba71fa-db46-45f0-a0f8-1a36f862da53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[ 7.81147375 11.57703876  8.12456869]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_DecisionTreeRegressor.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "DT = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha DTR\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l8NSwEODsMH",
        "outputId": "88122ccc-051b-4804-fff8-a4be1304f59d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[ 7.50377726  7.50377726 10.31592888]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv(\"Datos_imputados_data_2.csv\").iloc[-3:] \n",
        "del df2[\"Unnamed: 0\"]\n",
        "df2 = df2[df2.columns[[0,2,3,4,7,9,11,13,14,15,16,17,18,20,21,22,24,25,26]]]\n",
        "\n",
        "data_folder = \"drive/MyDrive/output_benchmark/\" #nombre de la carpeta contenedora\n",
        "scaled_data_test = scaler.fit_transform(df2.drop([\"Tasa de desocupación \", \"Fecha\"], axis=1))\n",
        "pickled_model = pickle.load(open(f'{data_folder}finalized_model_MLPRegressor.sav', 'rb')) # AQUI SE CAMBIA EL MODELO A UTILIZAR POR UNOS DE LOS QUE SE NOMBRAN ARRIBA\n",
        "tasa_desocupacion_predicha = pickled_model.predict(scaled_data_test) #Predict\n",
        "print(f\"La tasa de desocupación para la muestra ingresada es de:{tasa_desocupacion_predicha}\")\n",
        "MLP = pd.DataFrame(data = tasa_desocupacion_predicha,columns=[\"Tasa de desocupación predicha MLP\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bhQyjYEDslO",
        "outputId": "cd40eb43-b726-40b2-e734-2446cebc89af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La tasa de desocupación para la muestra ingresada es de:[ 7.68645108 18.04309271  9.21328662]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "final = pd.concat([df2[\"Tasa de desocupación \"].reset_index().drop(\"index\",axis=1),KNN],axis=1)\n",
        "final = pd.concat([final,DT],axis=1)\n",
        "final = pd.concat([final,SVR],axis=1)\n",
        "\n",
        "final = pd.concat([final,RFR],axis=1)\n",
        "\n",
        "final = pd.concat([final,lasso],axis=1)\n",
        "final = pd.concat([final,MLP],axis=1)\n",
        "final.index = df2[\"Fecha\"]\n",
        "final.to_csv(\"Resultados_regresión.csv\")"
      ],
      "metadata": {
        "id": "w5sTFWUQE9kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final\n",
        "for x in final:\n",
        "  if x != \"Tasa de desocupación \":\n",
        "    final[x] = final[\"Tasa de desocupación \"] - final[x]"
      ],
      "metadata": {
        "id": "dOdhF0LuEAc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "eoNpbU2hFSsT",
        "outputId": "f4e2874c-4b1b-4255-897f-a347c3a23276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Tasa de desocupación   Tasa de desocupación predicha KNN  \\\n",
              "Fecha                                                                  \n",
              "2023-02-01               8.367641                           0.556167   \n",
              "2023-03-01               8.808479                          -2.768560   \n",
              "2023-04-01               8.659709                           0.535140   \n",
              "\n",
              "            Tasa de desocupación predicha DTR  \\\n",
              "Fecha                                           \n",
              "2023-02-01                           0.863863   \n",
              "2023-03-01                           1.304702   \n",
              "2023-04-01                          -1.656220   \n",
              "\n",
              "            Tasa de desocupación predicha SVR  \\\n",
              "Fecha                                           \n",
              "2023-02-01                           0.436485   \n",
              "2023-03-01                           0.587306   \n",
              "2023-04-01                           0.582684   \n",
              "\n",
              "            Tasa de desocupación predicha RFR  \\\n",
              "Fecha                                           \n",
              "2023-02-01                           0.591806   \n",
              "2023-03-01                           1.031528   \n",
              "2023-04-01                          -1.898400   \n",
              "\n",
              "            Tasa de desocupación predicha LASSO  \\\n",
              "Fecha                                             \n",
              "2023-02-01                            -2.162173   \n",
              "2023-03-01                            -9.816009   \n",
              "2023-04-01                             0.525473   \n",
              "\n",
              "            Tasa de desocupación predicha MLP  \n",
              "Fecha                                          \n",
              "2023-02-01                           0.681190  \n",
              "2023-03-01                          -9.234614  \n",
              "2023-04-01                          -0.553578  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54d3bb4f-aae3-4bd2-abbf-a11b631c7dbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tasa de desocupación</th>\n",
              "      <th>Tasa de desocupación predicha KNN</th>\n",
              "      <th>Tasa de desocupación predicha DTR</th>\n",
              "      <th>Tasa de desocupación predicha SVR</th>\n",
              "      <th>Tasa de desocupación predicha RFR</th>\n",
              "      <th>Tasa de desocupación predicha LASSO</th>\n",
              "      <th>Tasa de desocupación predicha MLP</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fecha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-02-01</th>\n",
              "      <td>8.367641</td>\n",
              "      <td>0.556167</td>\n",
              "      <td>0.863863</td>\n",
              "      <td>0.436485</td>\n",
              "      <td>0.591806</td>\n",
              "      <td>-2.162173</td>\n",
              "      <td>0.681190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01</th>\n",
              "      <td>8.808479</td>\n",
              "      <td>-2.768560</td>\n",
              "      <td>1.304702</td>\n",
              "      <td>0.587306</td>\n",
              "      <td>1.031528</td>\n",
              "      <td>-9.816009</td>\n",
              "      <td>-9.234614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-01</th>\n",
              "      <td>8.659709</td>\n",
              "      <td>0.535140</td>\n",
              "      <td>-1.656220</td>\n",
              "      <td>0.582684</td>\n",
              "      <td>-1.898400</td>\n",
              "      <td>0.525473</td>\n",
              "      <td>-0.553578</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54d3bb4f-aae3-4bd2-abbf-a11b631c7dbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54d3bb4f-aae3-4bd2-abbf-a11b631c7dbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54d3bb4f-aae3-4bd2-abbf-a11b631c7dbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3o8kJHV6Fj6d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}